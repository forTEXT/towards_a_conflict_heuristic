{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399ceaf1",
   "metadata": {},
   "source": [
    "# Towards a Conflict Heuristic (DH 2023)\n",
    "\n",
    "## 05. Sentiment Analysis\n",
    "\n",
    "Last updated: 20.04.2023\n",
    "\n",
    "julian.haeussler[at]tu-darmstadt.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e4e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "import glob\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678b4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa66e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in corpora\n",
    "\n",
    "with open('../Analyseergebnisse/pickled/230116_lst_lists_phrases_Romantik_core_LEMMATIZED.pkl', 'rb') as f:\n",
    "    lst_lists_phrases_Romantik_core_LEMMATIZED = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67305a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Analyseergebnisse/pickled/230116_lst_lists_phrases_Realismus_LEMMATIZED.pkl', 'rb') as f:\n",
    "    lst_lists_phrases_Realismus_LEMMATIZED = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3651a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Analyseergebnisse/pickled/230116_lst_lists_phrases_Naturalismus_LEMMATIZED.pkl', 'rb') as f:\n",
    "    lst_lists_phrases_Naturalismus_LEMMATIZED = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8defb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Analyseergebnisse/pickled/230116_lst_lists_phrases_Romantik_core_TOKENIZED.pkl', 'rb') as f:\n",
    "    lst_lists_phrases_Romantik_core_TOKENIZED = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a443ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Analyseergebnisse/pickled/230116_lst_lists_phrases_Realismus_TOKENIZED.pkl', 'rb') as f:\n",
    "    lst_lists_phrases_Realismus_TOKENIZED = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244814cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Analyseergebnisse/pickled/230116_lst_lists_phrases_Naturalismus_TOKENIZED.pkl', 'rb') as f:\n",
    "    lst_lists_phrases_Naturalismus_TOKENIZED = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0768eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76cf348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create phrase lists and word lists\n",
    "\n",
    "lst_phrases_Romantik_core_LEMMATIZED = [phrase for novel in lst_lists_phrases_Romantik_core_LEMMATIZED for phrase in novel]\n",
    "\n",
    "lst_words_Romantik_core_LEMMATIZED = [word for phrase in lst_phrases_Romantik_core_LEMMATIZED for word in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77348e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_phrases_Realismus_LEMMATIZED = [phrase for novel in lst_lists_phrases_Realismus_LEMMATIZED for phrase in novel]\n",
    "\n",
    "lst_words_Realismus_LEMMATIZED = [word for phrase in lst_phrases_Realismus_LEMMATIZED for word in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1218e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_phrases_Naturalismus_LEMMATIZED = [phrase for novel in lst_lists_phrases_Naturalismus_LEMMATIZED for phrase in novel]\n",
    "\n",
    "lst_words_Naturalismus_LEMMATIZED = [word for phrase in lst_phrases_Naturalismus_LEMMATIZED for word in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d75be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a805c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_phrases_Romantik_core_TOKENIZED = [phrase for novel in lst_lists_phrases_Romantik_core_TOKENIZED for phrase in novel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f72a2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_phrases_Realismus_TOKENIZED = [phrase for novel in lst_lists_phrases_Realismus_TOKENIZED for phrase in novel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37bc546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_phrases_Naturalismus_TOKENIZED = [phrase for novel in lst_lists_phrases_Naturalismus_TOKENIZED for phrase in novel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07a182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a8e51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in models\n",
    "\n",
    "model_Romantik = KeyedVectors.load('../Analyseergebnisse/models/230116_model_Romantik.kv')\n",
    "\n",
    "model_RealismusNaturalismus = KeyedVectors.load('../Analyseergebnisse/models/230116_model_RealismusNaturalismus.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032096b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ca2b261",
   "metadata": {},
   "source": [
    "#### Approach 1 (SA, adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8af0a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels\n",
    "\n",
    "lst_high_arousal = ['zornig','nervös','aufgeregt','entzückt']\n",
    "\n",
    "lst_high_valence = ['entzückt','glücklich','zufrieden','gelassen']\n",
    "\n",
    "lst_low_arousal =  ['gelassen','ruhig','müde','überdrüssig']\n",
    "\n",
    "lst_low_valence = ['überdrüssig','niedergeschlagen','bekümmert','zornig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157e1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757a5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions (see e.g. Jacobs et al. 2020)\n",
    "\n",
    "def emo_value(word, model, aspect = \"valence\"):\n",
    "    if aspect == \"valence\":\n",
    "        values_high = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_high_valence]\n",
    "        high = sum(values_high)/4\n",
    "        values_low = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_low_valence]\n",
    "        low = sum(values_low)/4\n",
    "    if aspect == \"arousal\":\n",
    "        values_high = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_high_arousal]\n",
    "        high = sum(values_high)/4\n",
    "        values_low = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_low_arousal]\n",
    "        low = sum(values_low)/4\n",
    "    \n",
    "    return (high - low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5adb2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotional_potential(valence, arousal):\n",
    "    return abs(valence) * arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055216d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca5df3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROMANTIK\n",
    "\n",
    "# create df\n",
    "\n",
    "df_VPs_Romantik_core = pd.DataFrame(columns=['phrase_tokenized', 'phrase_lemmatized','mean_val_adj', 'mean_aro_adj', 'mean_ep_adj',\n",
    "                                            'mean_val_noun', 'mean_aro_noun', 'mean_ep_noun', 'mean_conf_dornseiff', 'mean_conf_annotation',\n",
    "                                            'novel_title', 'novel_beg', 'novel_end', 'phrase_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2794ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Romantik_core['phrase_tokenized'] = lst_phrases_Romantik_core_TOKENIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4edca1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Romantik_core['phrase_lemmatized'] = lst_phrases_Romantik_core_LEMMATIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1c723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c2905df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dem, schutzgeist, bleibt, ein, treuer, sinn, ...</td>\n",
       "      <td>[der, schutzgeist, bleiben, einen, treu, sinn,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[so, ward, auch, mir, ein, hochgesellig, leben...</td>\n",
       "      <td>[so, ward, auch, sich, einen, hochgesellig, le...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wo, sich, die, worte, leicht, zum, lied, gere...</td>\n",
       "      <td>[wo, sich, der, wort, leicht, zum, lied, reihen]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mein, lied, und, ich, wir, bleiben, treu, erg...</td>\n",
       "      <td>[mein, lied, und, ich, ich, bleiben, treu, erg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, uns, hat, durch, melodie, geweiht]</td>\n",
       "      <td>[der, sich, haben, durch, melodie, weihen]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [dem, schutzgeist, bleibt, ein, treuer, sinn, ...   \n",
       "1  [so, ward, auch, mir, ein, hochgesellig, leben...   \n",
       "2  [wo, sich, die, worte, leicht, zum, lied, gere...   \n",
       "3  [mein, lied, und, ich, wir, bleiben, treu, erg...   \n",
       "4           [der, uns, hat, durch, melodie, geweiht]   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [der, schutzgeist, bleiben, einen, treu, sinn,...          NaN   \n",
       "1  [so, ward, auch, sich, einen, hochgesellig, le...          NaN   \n",
       "2   [wo, sich, der, wort, leicht, zum, lied, reihen]          NaN   \n",
       "3  [mein, lied, und, ich, ich, bleiben, treu, erg...          NaN   \n",
       "4         [der, sich, haben, durch, melodie, weihen]          NaN   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0          NaN         NaN           NaN           NaN          NaN   \n",
       "1          NaN         NaN           NaN           NaN          NaN   \n",
       "2          NaN         NaN           NaN           NaN          NaN   \n",
       "3          NaN         NaN           NaN           NaN          NaN   \n",
       "4          NaN         NaN           NaN           NaN          NaN   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation novel_title novel_beg novel_end  \\\n",
       "0                 NaN                  NaN         NaN       NaN       NaN   \n",
       "1                 NaN                  NaN         NaN       NaN       NaN   \n",
       "2                 NaN                  NaN         NaN       NaN       NaN   \n",
       "3                 NaN                  NaN         NaN       NaN       NaN   \n",
       "4                 NaN                  NaN         NaN       NaN       NaN   \n",
       "\n",
       "  phrase_pos  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0763db08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250852</th>\n",
       "      <td>[ , ruhig, modere, sein, gebein]</td>\n",
       "      <td>[ , ruhig, modere, mein, gebein]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250853</th>\n",
       "      <td>[friede, sei, mit, seiner, seele]</td>\n",
       "      <td>[friede, sein, mit, sich, seele]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250854</th>\n",
       "      <td>[die, erzählung, seiner, nachherigen, schicksa...</td>\n",
       "      <td>[der, erzählung, sich, nachherigen, schicksal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250855</th>\n",
       "      <td>[dahin, muß, ich, hier, dieselben, verweisen, 2]</td>\n",
       "      <td>[dahin, muß, ich, hier, derselbe, verweisen, 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250856</th>\n",
       "      <td>[eine, ausführlichere, erzählung, der, schicks...</td>\n",
       "      <td>[eine, ausführlich, erzählung, der, schicksal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         phrase_tokenized  \\\n",
       "250852                   [ , ruhig, modere, sein, gebein]   \n",
       "250853                  [friede, sei, mit, seiner, seele]   \n",
       "250854  [die, erzählung, seiner, nachherigen, schicksa...   \n",
       "250855   [dahin, muß, ich, hier, dieselben, verweisen, 2]   \n",
       "250856  [eine, ausführlichere, erzählung, der, schicks...   \n",
       "\n",
       "                                        phrase_lemmatized mean_val_adj  \\\n",
       "250852                   [ , ruhig, modere, mein, gebein]          NaN   \n",
       "250853                   [friede, sein, mit, sich, seele]          NaN   \n",
       "250854  [der, erzählung, sich, nachherigen, schicksal,...          NaN   \n",
       "250855    [dahin, muß, ich, hier, derselbe, verweisen, 2]          NaN   \n",
       "250856  [eine, ausführlich, erzählung, der, schicksal,...          NaN   \n",
       "\n",
       "       mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "250852          NaN         NaN           NaN           NaN          NaN   \n",
       "250853          NaN         NaN           NaN           NaN          NaN   \n",
       "250854          NaN         NaN           NaN           NaN          NaN   \n",
       "250855          NaN         NaN           NaN           NaN          NaN   \n",
       "250856          NaN         NaN           NaN           NaN          NaN   \n",
       "\n",
       "       mean_conf_dornseiff mean_conf_annotation novel_title novel_beg  \\\n",
       "250852                 NaN                  NaN         NaN       NaN   \n",
       "250853                 NaN                  NaN         NaN       NaN   \n",
       "250854                 NaN                  NaN         NaN       NaN   \n",
       "250855                 NaN                  NaN         NaN       NaN   \n",
       "250856                 NaN                  NaN         NaN       NaN   \n",
       "\n",
       "       novel_end phrase_pos  \n",
       "250852       NaN        NaN  \n",
       "250853       NaN        NaN  \n",
       "250854       NaN        NaN  \n",
       "250855       NaN        NaN  \n",
       "250856       NaN        NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394ba88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57271686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in novel titles\n",
    "\n",
    "lst_novels_titles = []\n",
    "\n",
    "lst_files_names = glob.glob(os.path.join(os.getcwd(), r\"C:\\Users\\Julian\\HESSENBOX-DA\\Projekte\\Konflikte\\Daten\\Romantik (abgeschlossen)\\TXT\\Kernkorpus\", \"*.txt\"))\n",
    "\n",
    "for entry in lst_files_names:\n",
    "    lst_novels_titles.append(re.search(r\"(?<=Kernkorpus\\\\)(.*)(?=.txt)\",entry).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f2a13f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Busse_der_Graefin_Dolores',\n",
       " 'Arnim_Achim_von_Die_Kronenwaechter_Erster_Band',\n",
       " 'Arnim_Achim_von_Die_Kronenwaechter_Zweiter_Band']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_novels_titles[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911dae3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9a35f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get novels lenghts in VPS\n",
    "\n",
    "lst_files_all = glob.glob(os.path.join(os.getcwd(), '..\\\\Analyseergebnisse\\\\pickled\\\\all', \"*.pkl\"))\n",
    "\n",
    "lst_novels_lens = []\n",
    "\n",
    "beginning = 0\n",
    "\n",
    "for i in range(0,len(lst_novels_titles)):\n",
    "    # list of phrases\n",
    "    lst_phrases_novel = []\n",
    "    \n",
    "    # iterate through folders \"all\"\n",
    "    for j in range(0,len(lst_files_all)):\n",
    "        if j%4 == 0:\n",
    "            name = re.search(r\"(?<=all\\\\)(.*)(?=_phrases_lemmatized)\",lst_files_all[j]).group(1)\n",
    "            if name == lst_novels_titles[i]:\n",
    "                with open(lst_files_all[j], 'rb') as f:\n",
    "                    lst_phrases_novel = pickle.load(f)\n",
    "                    \n",
    "    # get no. of phrases\n",
    "    len_novel = len(lst_phrases_novel)\n",
    "    \n",
    "    # set end as length of novel in phrases and add to list of lengths\n",
    "    end = beginning + len_novel\n",
    "    lst_novels_lens.append((beginning,end))\n",
    "    \n",
    "    # update beginning\n",
    "    beginning = lst_novels_lens[i][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d16744b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_novels_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fa2b182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 17603), (17603, 28562), (28562, 38464), (38464, 41231), (41231, 56319)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_novels_lens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e19c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca182605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new info to df\n",
    "\n",
    "for i in range(0,len(lst_novels_lens)):\n",
    "    beginning = lst_novels_lens[i][0]\n",
    "    end = lst_novels_lens[i][1]\n",
    "    for j in range(beginning,end):\n",
    "        df_VPs_Romantik_core.at[j,'novel_title'] = lst_novels_titles[i]\n",
    "        df_VPs_Romantik_core.at[j,'novel_beg'] = beginning #counting starts with 0 (!)\n",
    "        df_VPs_Romantik_core.at[j,'novel_end'] = end-1 #novel length in VPs is end+1\n",
    "        df_VPs_Romantik_core.at[j,'phrase_pos'] = int(j-beginning) #starts with 0 (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798614ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54f29ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dem, schutzgeist, bleibt, ein, treuer, sinn, ...</td>\n",
       "      <td>[der, schutzgeist, bleiben, einen, treu, sinn,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[so, ward, auch, mir, ein, hochgesellig, leben...</td>\n",
       "      <td>[so, ward, auch, sich, einen, hochgesellig, le...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wo, sich, die, worte, leicht, zum, lied, gere...</td>\n",
       "      <td>[wo, sich, der, wort, leicht, zum, lied, reihen]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mein, lied, und, ich, wir, bleiben, treu, erg...</td>\n",
       "      <td>[mein, lied, und, ich, ich, bleiben, treu, erg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, uns, hat, durch, melodie, geweiht]</td>\n",
       "      <td>[der, sich, haben, durch, melodie, weihen]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [dem, schutzgeist, bleibt, ein, treuer, sinn, ...   \n",
       "1  [so, ward, auch, mir, ein, hochgesellig, leben...   \n",
       "2  [wo, sich, die, worte, leicht, zum, lied, gere...   \n",
       "3  [mein, lied, und, ich, wir, bleiben, treu, erg...   \n",
       "4           [der, uns, hat, durch, melodie, geweiht]   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [der, schutzgeist, bleiben, einen, treu, sinn,...          NaN   \n",
       "1  [so, ward, auch, sich, einen, hochgesellig, le...          NaN   \n",
       "2   [wo, sich, der, wort, leicht, zum, lied, reihen]          NaN   \n",
       "3  [mein, lied, und, ich, ich, bleiben, treu, erg...          NaN   \n",
       "4         [der, sich, haben, durch, melodie, weihen]          NaN   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0          NaN         NaN           NaN           NaN          NaN   \n",
       "1          NaN         NaN           NaN           NaN          NaN   \n",
       "2          NaN         NaN           NaN           NaN          NaN   \n",
       "3          NaN         NaN           NaN           NaN          NaN   \n",
       "4          NaN         NaN           NaN           NaN          NaN   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation  \\\n",
       "0                 NaN                  NaN   \n",
       "1                 NaN                  NaN   \n",
       "2                 NaN                  NaN   \n",
       "3                 NaN                  NaN   \n",
       "4                 NaN                  NaN   \n",
       "\n",
       "                                         novel_title novel_beg novel_end  \\\n",
       "0  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "1  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "2  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "3  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "4  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "\n",
       "  phrase_pos  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2fcf9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250852</th>\n",
       "      <td>[ , ruhig, modere, sein, gebein]</td>\n",
       "      <td>[ , ruhig, modere, mein, gebein]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vulpius_Christian_August_Rinaldo_Rinaldini,_de...</td>\n",
       "      <td>231861</td>\n",
       "      <td>250856</td>\n",
       "      <td>18991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250853</th>\n",
       "      <td>[friede, sei, mit, seiner, seele]</td>\n",
       "      <td>[friede, sein, mit, sich, seele]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vulpius_Christian_August_Rinaldo_Rinaldini,_de...</td>\n",
       "      <td>231861</td>\n",
       "      <td>250856</td>\n",
       "      <td>18992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250854</th>\n",
       "      <td>[die, erzählung, seiner, nachherigen, schicksa...</td>\n",
       "      <td>[der, erzählung, sich, nachherigen, schicksal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vulpius_Christian_August_Rinaldo_Rinaldini,_de...</td>\n",
       "      <td>231861</td>\n",
       "      <td>250856</td>\n",
       "      <td>18993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250855</th>\n",
       "      <td>[dahin, muß, ich, hier, dieselben, verweisen, 2]</td>\n",
       "      <td>[dahin, muß, ich, hier, derselbe, verweisen, 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vulpius_Christian_August_Rinaldo_Rinaldini,_de...</td>\n",
       "      <td>231861</td>\n",
       "      <td>250856</td>\n",
       "      <td>18994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250856</th>\n",
       "      <td>[eine, ausführlichere, erzählung, der, schicks...</td>\n",
       "      <td>[eine, ausführlich, erzählung, der, schicksal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vulpius_Christian_August_Rinaldo_Rinaldini,_de...</td>\n",
       "      <td>231861</td>\n",
       "      <td>250856</td>\n",
       "      <td>18995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         phrase_tokenized  \\\n",
       "250852                   [ , ruhig, modere, sein, gebein]   \n",
       "250853                  [friede, sei, mit, seiner, seele]   \n",
       "250854  [die, erzählung, seiner, nachherigen, schicksa...   \n",
       "250855   [dahin, muß, ich, hier, dieselben, verweisen, 2]   \n",
       "250856  [eine, ausführlichere, erzählung, der, schicks...   \n",
       "\n",
       "                                        phrase_lemmatized mean_val_adj  \\\n",
       "250852                   [ , ruhig, modere, mein, gebein]          NaN   \n",
       "250853                   [friede, sein, mit, sich, seele]          NaN   \n",
       "250854  [der, erzählung, sich, nachherigen, schicksal,...          NaN   \n",
       "250855    [dahin, muß, ich, hier, derselbe, verweisen, 2]          NaN   \n",
       "250856  [eine, ausführlich, erzählung, der, schicksal,...          NaN   \n",
       "\n",
       "       mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "250852          NaN         NaN           NaN           NaN          NaN   \n",
       "250853          NaN         NaN           NaN           NaN          NaN   \n",
       "250854          NaN         NaN           NaN           NaN          NaN   \n",
       "250855          NaN         NaN           NaN           NaN          NaN   \n",
       "250856          NaN         NaN           NaN           NaN          NaN   \n",
       "\n",
       "       mean_conf_dornseiff mean_conf_annotation  \\\n",
       "250852                 NaN                  NaN   \n",
       "250853                 NaN                  NaN   \n",
       "250854                 NaN                  NaN   \n",
       "250855                 NaN                  NaN   \n",
       "250856                 NaN                  NaN   \n",
       "\n",
       "                                              novel_title novel_beg novel_end  \\\n",
       "250852  Vulpius_Christian_August_Rinaldo_Rinaldini,_de...    231861    250856   \n",
       "250853  Vulpius_Christian_August_Rinaldo_Rinaldini,_de...    231861    250856   \n",
       "250854  Vulpius_Christian_August_Rinaldo_Rinaldini,_de...    231861    250856   \n",
       "250855  Vulpius_Christian_August_Rinaldo_Rinaldini,_de...    231861    250856   \n",
       "250856  Vulpius_Christian_August_Rinaldo_Rinaldini,_de...    231861    250856   \n",
       "\n",
       "       phrase_pos  \n",
       "250852      18991  \n",
       "250853      18992  \n",
       "250854      18993  \n",
       "250855      18994  \n",
       "250856      18995  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd2918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d175ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine values for all types\n",
    "\n",
    "dict_profiles = {}\n",
    "lst_valence = []\n",
    "lst_arousal = []\n",
    "lst_potential = []\n",
    "\n",
    "for word in list(set(lst_words_Romantik_core_LEMMATIZED)):\n",
    "    try:\n",
    "        valence = emo_value(word, model_Romantik, \"valence\")\n",
    "        lst_valence.append(valence)\n",
    "        arousal = emo_value(word, model_Romantik, \"arousal\")\n",
    "        lst_arousal.append(arousal)\n",
    "        potential = emotional_potential(valence, arousal)\n",
    "        lst_potential.append(potential)\n",
    "        dict_profiles[word] = (valence, arousal, potential)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156c160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bc8bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA for all VPs\n",
    "\n",
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Romantik_core_LEMMATIZED:\n",
    "    \n",
    "    lst_valence_phrase = []\n",
    "    lst_arousal_phrase = []\n",
    "    lst_potential_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_valence_phrase.append(dict_profiles[word][0])\n",
    "        lst_arousal_phrase.append(dict_profiles[word][1])\n",
    "        lst_potential_phrase.append(dict_profiles[word][2])\n",
    "    \n",
    "    mean_val_phrase = sum(lst_valence_phrase) / len(lst_valence_phrase)\n",
    "    mean_aro_phrase = sum(lst_arousal_phrase) / len(lst_arousal_phrase)\n",
    "    mean_ep_phrase = sum(lst_potential_phrase) / len(lst_potential_phrase)\n",
    "    \n",
    "    df_VPs_Romantik_core.at[i,'mean_val_adj'] = mean_val_phrase\n",
    "    df_VPs_Romantik_core.at[i,'mean_aro_adj'] = mean_aro_phrase\n",
    "    df_VPs_Romantik_core.at[i,'mean_ep_adj'] = mean_ep_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63783603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dem, schutzgeist, bleibt, ein, treuer, sinn, ...</td>\n",
       "      <td>[der, schutzgeist, bleiben, einen, treu, sinn,...</td>\n",
       "      <td>-0.008388</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[so, ward, auch, mir, ein, hochgesellig, leben...</td>\n",
       "      <td>[so, ward, auch, sich, einen, hochgesellig, le...</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wo, sich, die, worte, leicht, zum, lied, gere...</td>\n",
       "      <td>[wo, sich, der, wort, leicht, zum, lied, reihen]</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mein, lied, und, ich, wir, bleiben, treu, erg...</td>\n",
       "      <td>[mein, lied, und, ich, ich, bleiben, treu, erg...</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>-0.011589</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, uns, hat, durch, melodie, geweiht]</td>\n",
       "      <td>[der, sich, haben, durch, melodie, weihen]</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [dem, schutzgeist, bleibt, ein, treuer, sinn, ...   \n",
       "1  [so, ward, auch, mir, ein, hochgesellig, leben...   \n",
       "2  [wo, sich, die, worte, leicht, zum, lied, gere...   \n",
       "3  [mein, lied, und, ich, wir, bleiben, treu, erg...   \n",
       "4           [der, uns, hat, durch, melodie, geweiht]   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [der, schutzgeist, bleiben, einen, treu, sinn,...    -0.008388   \n",
       "1  [so, ward, auch, sich, einen, hochgesellig, le...     0.000133   \n",
       "2   [wo, sich, der, wort, leicht, zum, lied, reihen]    -0.000316   \n",
       "3  [mein, lied, und, ich, ich, bleiben, treu, erg...    -0.002559   \n",
       "4         [der, sich, haben, durch, melodie, weihen]     0.021854   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0     0.007577   -0.000145           NaN           NaN          NaN   \n",
       "1    -0.000132   -0.000119           NaN           NaN          NaN   \n",
       "2    -0.002302   -0.000048           NaN           NaN          NaN   \n",
       "3    -0.011589   -0.000559           NaN           NaN          NaN   \n",
       "4     0.004098   -0.000289           NaN           NaN          NaN   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation  \\\n",
       "0                 NaN                  NaN   \n",
       "1                 NaN                  NaN   \n",
       "2                 NaN                  NaN   \n",
       "3                 NaN                  NaN   \n",
       "4                 NaN                  NaN   \n",
       "\n",
       "                                         novel_title novel_beg novel_end  \\\n",
       "0  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "1  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "2  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "3  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "4  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "\n",
       "  phrase_pos  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be25ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2ae8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REALISMUS\n",
    "\n",
    "# create df\n",
    "\n",
    "df_VPs_Realismus = pd.DataFrame(columns=['phrase_tokenized', 'phrase_lemmatized','mean_val_adj', 'mean_aro_adj', 'mean_ep_adj',\n",
    "                                            'mean_val_noun', 'mean_aro_noun', 'mean_ep_noun', 'mean_conf_dornseiff', 'mean_conf_annotation',\n",
    "                                            'novel_title', 'novel_beg', 'novel_end', 'phrase_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bcbb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Realismus['phrase_tokenized'] = lst_phrases_Realismus_TOKENIZED\n",
    "\n",
    "df_VPs_Realismus['phrase_lemmatized'] = lst_phrases_Realismus_LEMMATIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ff9fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in novel titles\n",
    "\n",
    "lst_novels_titles = []\n",
    "\n",
    "lst_files_names = glob.glob(os.path.join(os.getcwd(), r\"C:\\Users\\Public\\Data\\Korpuserstellung\\Realismus\", \"*.txt\"))\n",
    "\n",
    "for entry in lst_files_names:\n",
    "    lst_novels_titles.append(re.search(r\"(?<=Realismus\\\\)(.*)(?=.txt)\",entry).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cb02877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get novels lenghts in VPS\n",
    "\n",
    "lst_files_all = glob.glob(os.path.join(os.getcwd(), '..\\\\Analyseergebnisse\\\\pickled\\\\all', \"*.pkl\"))\n",
    "\n",
    "lst_novels_lens = []\n",
    "\n",
    "beginning = 0\n",
    "\n",
    "for i in range(0,len(lst_novels_titles)):\n",
    "    # get list of phrases\n",
    "    lst_phrases_novel = []\n",
    "    \n",
    "    # iterate through folders \"all\"\n",
    "    for j in range(0,len(lst_files_all)):\n",
    "        if j%4 == 0:\n",
    "            name = re.search(r\"(?<=all\\\\)(.*)(?=_phrases_lemmatized)\",lst_files_all[j]).group(1)\n",
    "            if name == lst_novels_titles[i]:\n",
    "                with open(lst_files_all[j], 'rb') as f:\n",
    "                    lst_phrases_novel = pickle.load(f)\n",
    "                    \n",
    "    # get no. of phrases\n",
    "    len_novel = len(lst_phrases_novel)\n",
    "    \n",
    "    # set end as length of novel in phrases and add to list of lengths\n",
    "    end = beginning + len_novel\n",
    "    lst_novels_lens.append((beginning,end))\n",
    "    \n",
    "    # update beginning\n",
    "    beginning = lst_novels_lens[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebae54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new info to df\n",
    "\n",
    "for i in range(0,len(lst_novels_lens)):\n",
    "    beginning = lst_novels_lens[i][0]\n",
    "    end = lst_novels_lens[i][1]\n",
    "    for j in range(beginning,end):\n",
    "        df_VPs_Realismus.at[j,'novel_title'] = lst_novels_titles[i]\n",
    "        df_VPs_Realismus.at[j,'novel_beg'] = beginning #counting starts with 0 (!)\n",
    "        df_VPs_Realismus.at[j,'novel_end'] = end-1 #novel length in VPs is end+1\n",
    "        df_VPs_Realismus.at[j,'phrase_pos'] = int(j-beginning) #starts with 0 (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2cb9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine values for all types\n",
    "\n",
    "dict_profiles = {}\n",
    "lst_valence = []\n",
    "lst_arousal = []\n",
    "lst_potential = []\n",
    "\n",
    "for word in list(set(lst_words_Realismus_LEMMATIZED)):\n",
    "    try:\n",
    "        valence = emo_value(word, model_RealismusNaturalismus, \"valence\")\n",
    "        lst_valence.append(valence)\n",
    "        arousal = emo_value(word, model_RealismusNaturalismus, \"arousal\")\n",
    "        lst_arousal.append(arousal)\n",
    "        potential = emotional_potential(valence, arousal)\n",
    "        lst_potential.append(potential)\n",
    "        dict_profiles[word] = (valence, arousal, potential)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6b04eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA for all VP\n",
    "\n",
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Realismus_LEMMATIZED:\n",
    "    \n",
    "    lst_valence_phrase = []\n",
    "    lst_arousal_phrase = []\n",
    "    lst_potential_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_valence_phrase.append(dict_profiles[word][0])\n",
    "        lst_arousal_phrase.append(dict_profiles[word][1])\n",
    "        lst_potential_phrase.append(dict_profiles[word][2])\n",
    "    \n",
    "    mean_val_phrase = sum(lst_valence_phrase) / len(lst_valence_phrase)\n",
    "    mean_aro_phrase = sum(lst_arousal_phrase) / len(lst_arousal_phrase)\n",
    "    mean_ep_phrase = sum(lst_potential_phrase) / len(lst_potential_phrase)\n",
    "    \n",
    "    df_VPs_Realismus.at[i,'mean_val_adj'] = mean_val_phrase\n",
    "    df_VPs_Realismus.at[i,'mean_aro_adj'] = mean_aro_phrase\n",
    "    df_VPs_Realismus.at[i,'mean_ep_adj'] = mean_ep_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e5d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbb368ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[es, klopfte, hart, und, kurz, an, die, tür]</td>\n",
       "      <td>[ich, klopfen, hart, und, kurz, an, der, tür]</td>\n",
       "      <td>-0.051287</td>\n",
       "      <td>-0.029731</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[obgleich, irene, seit, vielen, stunden, bald,...</td>\n",
       "      <td>[obgleich, irene, seit, viel, stunde, bald, wa...</td>\n",
       "      <td>-0.023664</td>\n",
       "      <td>-0.023765</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fuhr, sie, nun, doch, erschreckt, zusammen]</td>\n",
       "      <td>[fahren, ich, nun, doch, erschrecken, zusammen]</td>\n",
       "      <td>-0.043396</td>\n",
       "      <td>-0.008009</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[die, ganze, nacht, hatte, sie, keinen, rechte...</td>\n",
       "      <td>[der, ganze, nacht, haben, ich, kein, recht, s...</td>\n",
       "      <td>-0.027959</td>\n",
       "      <td>-0.033338</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[und, nun, schien, es, ihr, als, wären, ihre, ...</td>\n",
       "      <td>[und, nun, scheinen, ich, mein, als, sein, mei...</td>\n",
       "      <td>-0.037474</td>\n",
       "      <td>-0.032536</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0       [es, klopfte, hart, und, kurz, an, die, tür]   \n",
       "1  [obgleich, irene, seit, vielen, stunden, bald,...   \n",
       "2       [fuhr, sie, nun, doch, erschreckt, zusammen]   \n",
       "3  [die, ganze, nacht, hatte, sie, keinen, rechte...   \n",
       "4  [und, nun, schien, es, ihr, als, wären, ihre, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0      [ich, klopfen, hart, und, kurz, an, der, tür]    -0.051287   \n",
       "1  [obgleich, irene, seit, viel, stunde, bald, wa...    -0.023664   \n",
       "2    [fahren, ich, nun, doch, erschrecken, zusammen]    -0.043396   \n",
       "3  [der, ganze, nacht, haben, ich, kein, recht, s...    -0.027959   \n",
       "4  [und, nun, scheinen, ich, mein, als, sein, mei...    -0.037474   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.029731   -0.001594           NaN           NaN          NaN   \n",
       "1    -0.023765   -0.000829           NaN           NaN          NaN   \n",
       "2    -0.008009    0.001012           NaN           NaN          NaN   \n",
       "3    -0.033338   -0.001239           NaN           NaN          NaN   \n",
       "4    -0.032536   -0.001683           NaN           NaN          NaN   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation       novel_title novel_beg  \\\n",
       "0                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "1                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "2                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "3                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "4                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      6496          0  \n",
       "1      6496          1  \n",
       "2      6496          2  \n",
       "3      6496          3  \n",
       "4      6496          4  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Realismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee851e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63c4eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATURALISMUS\n",
    "\n",
    "# create df\n",
    "\n",
    "df_VPs_Naturalismus = pd.DataFrame(columns=['phrase_tokenized', 'phrase_lemmatized','mean_val_adj', 'mean_aro_adj', 'mean_ep_adj',\n",
    "                                            'mean_val_noun', 'mean_aro_noun', 'mean_ep_noun', 'mean_conf_dornseiff', 'mean_conf_annotation',\n",
    "                                            'novel_title', 'novel_beg', 'novel_end', 'phrase_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5afbc5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Naturalismus['phrase_tokenized'] = lst_phrases_Naturalismus_TOKENIZED\n",
    "\n",
    "df_VPs_Naturalismus['phrase_lemmatized'] = lst_phrases_Naturalismus_LEMMATIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67d7f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in novel titles\n",
    "\n",
    "lst_novels_titles = []\n",
    "\n",
    "lst_files_names = glob.glob(os.path.join(os.getcwd(), r\"C:\\Users\\Public\\Data\\Korpuserstellung\\Naturalismus\", \"*.txt\"))\n",
    "\n",
    "for entry in lst_files_names:\n",
    "    lst_novels_titles.append(re.search(r\"(?<=Naturalismus\\\\)(.*)(?=.txt)\",entry).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "749d604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get novels lenghts in VPS\n",
    "\n",
    "lst_files_all = glob.glob(os.path.join(os.getcwd(), '..\\\\Analyseergebnisse\\\\pickled\\\\all', \"*.pkl\"))\n",
    "\n",
    "lst_novels_lens = []\n",
    "\n",
    "beginning = 0\n",
    "\n",
    "for i in range(0,len(lst_novels_titles)):\n",
    "    # get list of phrases\n",
    "    lst_phrases_novel = []\n",
    "    \n",
    "    # iterate through folders \"all\"\n",
    "    for j in range(0,len(lst_files_all)):\n",
    "        if j%4 == 0:\n",
    "            name = re.search(r\"(?<=all\\\\)(.*)(?=_phrases_lemmatized)\",lst_files_all[j]).group(1)\n",
    "            if name == lst_novels_titles[i]:\n",
    "                with open(lst_files_all[j], 'rb') as f:\n",
    "                    lst_phrases_novel = pickle.load(f)\n",
    "                    \n",
    "    # get no. of phrases\n",
    "    len_novel = len(lst_phrases_novel)\n",
    "    \n",
    "    # set end as length of novel in phrases and add to list of lengths\n",
    "    end = beginning + len_novel\n",
    "    lst_novels_lens.append((beginning,end))\n",
    "    \n",
    "    # update beginning\n",
    "    beginning = lst_novels_lens[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20939aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new info to df\n",
    "\n",
    "for i in range(0,len(lst_novels_lens)):\n",
    "    beginning = lst_novels_lens[i][0]\n",
    "    end = lst_novels_lens[i][1]\n",
    "    for j in range(beginning,end):\n",
    "        df_VPs_Naturalismus.at[j,'novel_title'] = lst_novels_titles[i]\n",
    "        df_VPs_Naturalismus.at[j,'novel_beg'] = beginning #counting starts with 0 (!)\n",
    "        df_VPs_Naturalismus.at[j,'novel_end'] = end-1 #novel length in VPs is end+1\n",
    "        df_VPs_Naturalismus.at[j,'phrase_pos'] = int(j-beginning) #starts with 0 (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cf1252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine values for all types\n",
    "\n",
    "dict_profiles = {}\n",
    "lst_valence = []\n",
    "lst_arousal = []\n",
    "lst_potential = []\n",
    "\n",
    "for word in list(set(lst_words_Naturalismus_LEMMATIZED)):\n",
    "    try:\n",
    "        valence = emo_value(word, model_RealismusNaturalismus, \"valence\")\n",
    "        lst_valence.append(valence)\n",
    "        arousal = emo_value(word, model_RealismusNaturalismus, \"arousal\")\n",
    "        lst_arousal.append(arousal)\n",
    "        potential = emotional_potential(valence, arousal)\n",
    "        lst_potential.append(potential)\n",
    "        dict_profiles[word] = (valence, arousal, potential)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be1138b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA for all VP\n",
    "\n",
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Naturalismus_LEMMATIZED:\n",
    "    \n",
    "    lst_valence_phrase = []\n",
    "    lst_arousal_phrase = []\n",
    "    lst_potential_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_valence_phrase.append(dict_profiles[word][0])\n",
    "        lst_arousal_phrase.append(dict_profiles[word][1])\n",
    "        lst_potential_phrase.append(dict_profiles[word][2])\n",
    "    \n",
    "    mean_val_phrase = sum(lst_valence_phrase) / len(lst_valence_phrase)\n",
    "    mean_aro_phrase = sum(lst_arousal_phrase) / len(lst_arousal_phrase)\n",
    "    mean_ep_phrase = sum(lst_potential_phrase) / len(lst_potential_phrase)\n",
    "    \n",
    "    df_VPs_Naturalismus.at[i,'mean_val_adj'] = mean_val_phrase\n",
    "    df_VPs_Naturalismus.at[i,'mean_aro_adj'] = mean_aro_phrase\n",
    "    df_VPs_Naturalismus.at[i,'mean_ep_adj'] = mean_ep_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d4773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2d7d4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, der, morgenstille, war, nichts, vernehmba...</td>\n",
       "      <td>[in, der, morgenstille, sein, nichts, vernehmb...</td>\n",
       "      <td>-0.041573</td>\n",
       "      <td>-0.009479</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[die, sich, nicht, weit, von, der, russischen,...</td>\n",
       "      <td>[der, sich, nicht, weit, von, der, russisch, h...</td>\n",
       "      <td>-0.017482</td>\n",
       "      <td>-0.012251</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[die, breite, ungepflasterte, straße, die, sic...</td>\n",
       "      <td>[der, breit, ungepflasterte, straße, der, sich...</td>\n",
       "      <td>-0.023813</td>\n",
       "      <td>-0.023564</td>\n",
       "      <td>-0.00089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dann, holperte, ein, leiterwagen, mit, einige...</td>\n",
       "      <td>[dann, holpern, einen, leiterwagen, mit, einig...</td>\n",
       "      <td>-0.05482</td>\n",
       "      <td>-0.040984</td>\n",
       "      <td>-0.00252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, fuhrmann, kletterte, von, seinem, sitz, ...</td>\n",
       "      <td>[der, fuhrmann, klettern, von, mein, sitz, wer...</td>\n",
       "      <td>-0.04453</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [in, der, morgenstille, war, nichts, vernehmba...   \n",
       "1  [die, sich, nicht, weit, von, der, russischen,...   \n",
       "2  [die, breite, ungepflasterte, straße, die, sic...   \n",
       "3  [dann, holperte, ein, leiterwagen, mit, einige...   \n",
       "4  [der, fuhrmann, kletterte, von, seinem, sitz, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [in, der, morgenstille, sein, nichts, vernehmb...    -0.041573   \n",
       "1  [der, sich, nicht, weit, von, der, russisch, h...    -0.017482   \n",
       "2  [der, breit, ungepflasterte, straße, der, sich...    -0.023813   \n",
       "3  [dann, holpern, einen, leiterwagen, mit, einig...     -0.05482   \n",
       "4  [der, fuhrmann, klettern, von, mein, sitz, wer...     -0.04453   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.009479   -0.000255           NaN           NaN          NaN   \n",
       "1    -0.012251   -0.000511           NaN           NaN          NaN   \n",
       "2    -0.023564    -0.00089           NaN           NaN          NaN   \n",
       "3    -0.040984    -0.00252           NaN           NaN          NaN   \n",
       "4    -0.022021   -0.001098           NaN           NaN          NaN   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation              novel_title novel_beg  \\\n",
       "0                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "1                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "2                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "3                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "4                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      8249          0  \n",
       "1      8249          1  \n",
       "2      8249          2  \n",
       "3      8249          3  \n",
       "4      8249          4  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Naturalismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc820f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04924ab6",
   "metadata": {},
   "source": [
    "#### Approach 1 (SA, nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e131d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels\n",
    "\n",
    "lst_high_valence = ['behagen', 'glück', 'freude', 'stolz', 'hilfe', 'befriedigung', 'erstaunen']\n",
    "\n",
    "lst_low_valence = ['ekel', 'verlegenheit', 'sorge', 'traurigkeit', 'schande']\n",
    "\n",
    "lst_arousal_total = ['vergnügen', 'zorn', 'verachtung', 'behagen', 'ekel', 'verlegenheit', 'erregung', 'sorge', 'glück', 'interesse', 'freude', 'hilfe', 'traurigkeit', 'befriedigung']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f908d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb7447ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update function\n",
    "\n",
    "def emo_value(word, model, aspect = \"valence\"):\n",
    "    if aspect == \"valence\":\n",
    "        values_high = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_high_valence]\n",
    "        high = sum(values_high)/len(lst_high_valence)\n",
    "        values_low = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_low_valence]\n",
    "        low = sum(values_low)/len(lst_low_valence)\n",
    "        final_value = (high-low) \n",
    "    if aspect == \"arousal\":\n",
    "        values_all = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_arousal_total]\n",
    "        final_value = sum(values_all)/len(lst_arousal_total)\n",
    "        \n",
    "    return final_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f04229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14701f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROMANTIK\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_profiles = {}\n",
    "lst_valence = []\n",
    "lst_arousal = []\n",
    "lst_potential = []\n",
    "\n",
    "for word in list(set(lst_words_Romantik_core_LEMMATIZED)):\n",
    "    try:\n",
    "        valence = emo_value(word, model_Romantik, \"valence\")\n",
    "        lst_valence.append(valence)\n",
    "        arousal = emo_value(word, model_Romantik, \"arousal\")\n",
    "        lst_arousal.append(arousal)\n",
    "        potential = emotional_potential(valence, arousal)\n",
    "        lst_potential.append(potential)\n",
    "        dict_profiles[word] = (valence, arousal, potential)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a365a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA for all VPs\n",
    "\n",
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Romantik_core_LEMMATIZED:\n",
    "    \n",
    "    lst_valence_phrase = []\n",
    "    lst_arousal_phrase = []\n",
    "    lst_potential_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_valence_phrase.append(dict_profiles[word][0])\n",
    "        lst_arousal_phrase.append(dict_profiles[word][1])\n",
    "        lst_potential_phrase.append(dict_profiles[word][2])\n",
    "    \n",
    "    mean_val_phrase = sum(lst_valence_phrase) / len(lst_valence_phrase)\n",
    "    mean_aro_phrase = sum(lst_arousal_phrase) / len(lst_arousal_phrase)\n",
    "    mean_ep_phrase = sum(lst_potential_phrase) / len(lst_potential_phrase)\n",
    "    \n",
    "    df_VPs_Romantik_core.at[i,'mean_val_noun'] = mean_val_phrase\n",
    "    df_VPs_Romantik_core.at[i,'mean_aro_noun'] = mean_aro_phrase\n",
    "    df_VPs_Romantik_core.at[i,'mean_ep_noun'] = mean_ep_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff2fe92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dem, schutzgeist, bleibt, ein, treuer, sinn, ...</td>\n",
       "      <td>[der, schutzgeist, bleiben, einen, treu, sinn,...</td>\n",
       "      <td>-0.008388</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.224101</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[so, ward, auch, mir, ein, hochgesellig, leben...</td>\n",
       "      <td>[so, ward, auch, sich, einen, hochgesellig, le...</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wo, sich, die, worte, leicht, zum, lied, gere...</td>\n",
       "      <td>[wo, sich, der, wort, leicht, zum, lied, reihen]</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.211023</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mein, lied, und, ich, wir, bleiben, treu, erg...</td>\n",
       "      <td>[mein, lied, und, ich, ich, bleiben, treu, erg...</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>-0.011589</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.267624</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, uns, hat, durch, melodie, geweiht]</td>\n",
       "      <td>[der, sich, haben, durch, melodie, weihen]</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.249832</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [dem, schutzgeist, bleibt, ein, treuer, sinn, ...   \n",
       "1  [so, ward, auch, mir, ein, hochgesellig, leben...   \n",
       "2  [wo, sich, die, worte, leicht, zum, lied, gere...   \n",
       "3  [mein, lied, und, ich, wir, bleiben, treu, erg...   \n",
       "4           [der, uns, hat, durch, melodie, geweiht]   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [der, schutzgeist, bleiben, einen, treu, sinn,...    -0.008388   \n",
       "1  [so, ward, auch, sich, einen, hochgesellig, le...     0.000133   \n",
       "2   [wo, sich, der, wort, leicht, zum, lied, reihen]    -0.000316   \n",
       "3  [mein, lied, und, ich, ich, bleiben, treu, erg...    -0.002559   \n",
       "4         [der, sich, haben, durch, melodie, weihen]     0.021854   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0     0.007577   -0.000145      0.007036      0.224101     0.006323   \n",
       "1    -0.000132   -0.000119      0.007223      0.257948     0.005676   \n",
       "2    -0.002302   -0.000048      0.009215      0.211023     0.005506   \n",
       "3    -0.011589   -0.000559      0.013513      0.267624     0.006237   \n",
       "4     0.004098   -0.000289     -0.004865      0.249832     0.006091   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation  \\\n",
       "0                 NaN                  NaN   \n",
       "1                 NaN                  NaN   \n",
       "2                 NaN                  NaN   \n",
       "3                 NaN                  NaN   \n",
       "4                 NaN                  NaN   \n",
       "\n",
       "                                         novel_title novel_beg novel_end  \\\n",
       "0  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "1  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "2  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "3  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "4  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "\n",
       "  phrase_pos  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73223384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fe38410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REALISMUS\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_profiles = {}\n",
    "lst_valence = []\n",
    "lst_arousal = []\n",
    "lst_potential = []\n",
    "\n",
    "for word in list(set(lst_words_Realismus_LEMMATIZED)):\n",
    "    try:\n",
    "        valence = emo_value(word, model_RealismusNaturalismus, \"valence\")\n",
    "        lst_valence.append(valence)\n",
    "        arousal = emo_value(word, model_RealismusNaturalismus, \"arousal\")\n",
    "        lst_arousal.append(arousal)\n",
    "        potential = emotional_potential(valence, arousal)\n",
    "        lst_potential.append(potential)\n",
    "        dict_profiles[word] = (valence, arousal, potential)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "379cb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA for all VPs\n",
    "\n",
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Realismus_LEMMATIZED:\n",
    "    \n",
    "    lst_valence_phrase = []\n",
    "    lst_arousal_phrase = []\n",
    "    lst_potential_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_valence_phrase.append(dict_profiles[word][0])\n",
    "        lst_arousal_phrase.append(dict_profiles[word][1])\n",
    "        lst_potential_phrase.append(dict_profiles[word][2])\n",
    "    \n",
    "    mean_val_phrase = sum(lst_valence_phrase) / len(lst_valence_phrase)\n",
    "    mean_aro_phrase = sum(lst_arousal_phrase) / len(lst_arousal_phrase)\n",
    "    mean_ep_phrase = sum(lst_potential_phrase) / len(lst_potential_phrase)\n",
    "    \n",
    "    df_VPs_Realismus.at[i,'mean_val_noun'] = mean_val_phrase\n",
    "    df_VPs_Realismus.at[i,'mean_aro_noun'] = mean_aro_phrase\n",
    "    df_VPs_Realismus.at[i,'mean_ep_noun'] = mean_ep_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9b0bab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[es, klopfte, hart, und, kurz, an, die, tür]</td>\n",
       "      <td>[ich, klopfen, hart, und, kurz, an, der, tür]</td>\n",
       "      <td>-0.051287</td>\n",
       "      <td>-0.029731</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>-0.014026</td>\n",
       "      <td>0.239272</td>\n",
       "      <td>0.00693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[obgleich, irene, seit, vielen, stunden, bald,...</td>\n",
       "      <td>[obgleich, irene, seit, viel, stunde, bald, wa...</td>\n",
       "      <td>-0.023664</td>\n",
       "      <td>-0.023765</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.028803</td>\n",
       "      <td>0.25432</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fuhr, sie, nun, doch, erschreckt, zusammen]</td>\n",
       "      <td>[fahren, ich, nun, doch, erschrecken, zusammen]</td>\n",
       "      <td>-0.043396</td>\n",
       "      <td>-0.008009</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.033831</td>\n",
       "      <td>0.252944</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[die, ganze, nacht, hatte, sie, keinen, rechte...</td>\n",
       "      <td>[der, ganze, nacht, haben, ich, kein, recht, s...</td>\n",
       "      <td>-0.027959</td>\n",
       "      <td>-0.033338</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.035174</td>\n",
       "      <td>0.273068</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[und, nun, schien, es, ihr, als, wären, ihre, ...</td>\n",
       "      <td>[und, nun, scheinen, ich, mein, als, sein, mei...</td>\n",
       "      <td>-0.037474</td>\n",
       "      <td>-0.032536</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>-0.044963</td>\n",
       "      <td>0.29948</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0       [es, klopfte, hart, und, kurz, an, die, tür]   \n",
       "1  [obgleich, irene, seit, vielen, stunden, bald,...   \n",
       "2       [fuhr, sie, nun, doch, erschreckt, zusammen]   \n",
       "3  [die, ganze, nacht, hatte, sie, keinen, rechte...   \n",
       "4  [und, nun, schien, es, ihr, als, wären, ihre, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0      [ich, klopfen, hart, und, kurz, an, der, tür]    -0.051287   \n",
       "1  [obgleich, irene, seit, viel, stunde, bald, wa...    -0.023664   \n",
       "2    [fahren, ich, nun, doch, erschrecken, zusammen]    -0.043396   \n",
       "3  [der, ganze, nacht, haben, ich, kein, recht, s...    -0.027959   \n",
       "4  [und, nun, scheinen, ich, mein, als, sein, mei...    -0.037474   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.029731   -0.001594     -0.014026      0.239272      0.00693   \n",
       "1    -0.023765   -0.000829     -0.028803       0.25432     0.008266   \n",
       "2    -0.008009    0.001012     -0.033831      0.252944     0.009461   \n",
       "3    -0.033338   -0.001239     -0.035174      0.273068     0.011571   \n",
       "4    -0.032536   -0.001683     -0.044963       0.29948     0.015282   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation       novel_title novel_beg  \\\n",
       "0                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "1                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "2                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "3                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "4                 NaN                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      6496          0  \n",
       "1      6496          1  \n",
       "2      6496          2  \n",
       "3      6496          3  \n",
       "4      6496          4  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Realismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644f145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f4c534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATURALISMUS\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_profiles = {}\n",
    "lst_valence = []\n",
    "lst_arousal = []\n",
    "lst_potential = []\n",
    "\n",
    "for word in list(set(lst_words_Naturalismus_LEMMATIZED)):\n",
    "    try:\n",
    "        valence = emo_value(word, model_RealismusNaturalismus, \"valence\")\n",
    "        lst_valence.append(valence)\n",
    "        arousal = emo_value(word, model_RealismusNaturalismus, \"arousal\")\n",
    "        lst_arousal.append(arousal)\n",
    "        potential = emotional_potential(valence, arousal)\n",
    "        lst_potential.append(potential)\n",
    "        dict_profiles[word] = (valence, arousal, potential)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b959fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA for all VPs\n",
    "\n",
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Naturalismus_LEMMATIZED:\n",
    "    \n",
    "    lst_valence_phrase = []\n",
    "    lst_arousal_phrase = []\n",
    "    lst_potential_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_valence_phrase.append(dict_profiles[word][0])\n",
    "        lst_arousal_phrase.append(dict_profiles[word][1])\n",
    "        lst_potential_phrase.append(dict_profiles[word][2])\n",
    "    \n",
    "    mean_val_phrase = sum(lst_valence_phrase) / len(lst_valence_phrase)\n",
    "    mean_aro_phrase = sum(lst_arousal_phrase) / len(lst_arousal_phrase)\n",
    "    mean_ep_phrase = sum(lst_potential_phrase) / len(lst_potential_phrase)\n",
    "    \n",
    "    df_VPs_Naturalismus.at[i,'mean_val_noun'] = mean_val_phrase\n",
    "    df_VPs_Naturalismus.at[i,'mean_aro_noun'] = mean_aro_phrase\n",
    "    df_VPs_Naturalismus.at[i,'mean_ep_noun'] = mean_ep_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf351a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, der, morgenstille, war, nichts, vernehmba...</td>\n",
       "      <td>[in, der, morgenstille, sein, nichts, vernehmb...</td>\n",
       "      <td>-0.041573</td>\n",
       "      <td>-0.009479</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.018016</td>\n",
       "      <td>0.236784</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[die, sich, nicht, weit, von, der, russischen,...</td>\n",
       "      <td>[der, sich, nicht, weit, von, der, russisch, h...</td>\n",
       "      <td>-0.017482</td>\n",
       "      <td>-0.012251</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.002285</td>\n",
       "      <td>0.230448</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[die, breite, ungepflasterte, straße, die, sic...</td>\n",
       "      <td>[der, breit, ungepflasterte, straße, der, sich...</td>\n",
       "      <td>-0.023813</td>\n",
       "      <td>-0.023564</td>\n",
       "      <td>-0.00089</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>0.223625</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dann, holperte, ein, leiterwagen, mit, einige...</td>\n",
       "      <td>[dann, holpern, einen, leiterwagen, mit, einig...</td>\n",
       "      <td>-0.05482</td>\n",
       "      <td>-0.040984</td>\n",
       "      <td>-0.00252</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.213727</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, fuhrmann, kletterte, von, seinem, sitz, ...</td>\n",
       "      <td>[der, fuhrmann, klettern, von, mein, sitz, wer...</td>\n",
       "      <td>-0.04453</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.015741</td>\n",
       "      <td>0.23927</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [in, der, morgenstille, war, nichts, vernehmba...   \n",
       "1  [die, sich, nicht, weit, von, der, russischen,...   \n",
       "2  [die, breite, ungepflasterte, straße, die, sic...   \n",
       "3  [dann, holperte, ein, leiterwagen, mit, einige...   \n",
       "4  [der, fuhrmann, kletterte, von, seinem, sitz, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [in, der, morgenstille, sein, nichts, vernehmb...    -0.041573   \n",
       "1  [der, sich, nicht, weit, von, der, russisch, h...    -0.017482   \n",
       "2  [der, breit, ungepflasterte, straße, der, sich...    -0.023813   \n",
       "3  [dann, holpern, einen, leiterwagen, mit, einig...     -0.05482   \n",
       "4  [der, fuhrmann, klettern, von, mein, sitz, wer...     -0.04453   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.009479   -0.000255     -0.018016      0.236784     0.005706   \n",
       "1    -0.012251   -0.000511     -0.002285      0.230448       0.0063   \n",
       "2    -0.023564    -0.00089     -0.005926      0.223625     0.005873   \n",
       "3    -0.040984    -0.00252     -0.011334      0.213727     0.004154   \n",
       "4    -0.022021   -0.001098     -0.015741       0.23927     0.005927   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation              novel_title novel_beg  \\\n",
       "0                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "1                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "2                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "3                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "4                 NaN                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      8249          0  \n",
       "1      8249          1  \n",
       "2      8249          2  \n",
       "3      8249          3  \n",
       "4      8249          4  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Naturalismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e0096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "419c811f",
   "metadata": {},
   "source": [
    "#### Approach 2 (Dornseiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9c2df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels\n",
    "\n",
    "lst_high_conflict = ['töten',\n",
    " 'unglück',\n",
    " 'gefahr',\n",
    " 'furcht',\n",
    " 'schrecken',\n",
    " 'streit',\n",
    " 'kampf',\n",
    " 'quälen',\n",
    " 'rache',\n",
    " 'gewalt',\n",
    " 'waffe',\n",
    " 'schutz']\n",
    "\n",
    "lst_low_conflict = ['glück', 'leicht', 'lust', 'bewundern', 'schönheit', 'friede']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34a655f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update function\n",
    "\n",
    "def conf_value(word, model):\n",
    "    values_high = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_high_conflict]\n",
    "    high = sum(values_high)/len(lst_high_conflict)\n",
    "    values_low = [cosine_similarity([model.get_vector(label),model.get_vector(word)])[0,1] for label in lst_low_conflict]\n",
    "    low = sum(values_low)/len(lst_low_conflict)\n",
    "    \n",
    "    return (high - low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82721a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "434db5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROMANTIK\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_conflict = {}\n",
    "lst_conflict = []\n",
    "\n",
    "for word in list(set(lst_words_Romantik_core_LEMMATIZED)):\n",
    "    try:\n",
    "        conflict_value = conf_value(word, model_Romantik)\n",
    "        lst_conflict.append(conflict_value)\n",
    "        dict_conflict[word] = conflict_value\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24128933",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Romantik_core_LEMMATIZED:\n",
    "    \n",
    "    lst_conflict_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_conflict_phrase.append(dict_conflict[word])\n",
    "    \n",
    "    mean_conf_phrase = sum(lst_conflict_phrase) / len(lst_conflict_phrase)\n",
    "    \n",
    "    df_VPs_Romantik_core.at[i,'mean_conf_dornseiff'] = mean_conf_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "29f44653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dem, schutzgeist, bleibt, ein, treuer, sinn, ...</td>\n",
       "      <td>[der, schutzgeist, bleiben, einen, treu, sinn,...</td>\n",
       "      <td>-0.008388</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.224101</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[so, ward, auch, mir, ein, hochgesellig, leben...</td>\n",
       "      <td>[so, ward, auch, sich, einen, hochgesellig, le...</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>-0.007146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wo, sich, die, worte, leicht, zum, lied, gere...</td>\n",
       "      <td>[wo, sich, der, wort, leicht, zum, lied, reihen]</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.211023</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>-0.01941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mein, lied, und, ich, wir, bleiben, treu, erg...</td>\n",
       "      <td>[mein, lied, und, ich, ich, bleiben, treu, erg...</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>-0.011589</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.267624</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, uns, hat, durch, melodie, geweiht]</td>\n",
       "      <td>[der, sich, haben, durch, melodie, weihen]</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.249832</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>-0.008013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [dem, schutzgeist, bleibt, ein, treuer, sinn, ...   \n",
       "1  [so, ward, auch, mir, ein, hochgesellig, leben...   \n",
       "2  [wo, sich, die, worte, leicht, zum, lied, gere...   \n",
       "3  [mein, lied, und, ich, wir, bleiben, treu, erg...   \n",
       "4           [der, uns, hat, durch, melodie, geweiht]   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [der, schutzgeist, bleiben, einen, treu, sinn,...    -0.008388   \n",
       "1  [so, ward, auch, sich, einen, hochgesellig, le...     0.000133   \n",
       "2   [wo, sich, der, wort, leicht, zum, lied, reihen]    -0.000316   \n",
       "3  [mein, lied, und, ich, ich, bleiben, treu, erg...    -0.002559   \n",
       "4         [der, sich, haben, durch, melodie, weihen]     0.021854   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0     0.007577   -0.000145      0.007036      0.224101     0.006323   \n",
       "1    -0.000132   -0.000119      0.007223      0.257948     0.005676   \n",
       "2    -0.002302   -0.000048      0.009215      0.211023     0.005506   \n",
       "3    -0.011589   -0.000559      0.013513      0.267624     0.006237   \n",
       "4     0.004098   -0.000289     -0.004865      0.249832     0.006091   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation  \\\n",
       "0            0.004102                  NaN   \n",
       "1           -0.007146                  NaN   \n",
       "2            -0.01941                  NaN   \n",
       "3            0.006048                  NaN   \n",
       "4           -0.008013                  NaN   \n",
       "\n",
       "                                         novel_title novel_beg novel_end  \\\n",
       "0  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "1  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "2  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "3  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "4  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "\n",
       "  phrase_pos  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0301c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc9f22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REALISMUS\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_conflict = {}\n",
    "lst_conflict = []\n",
    "\n",
    "for word in list(set(lst_words_Realismus_LEMMATIZED)):\n",
    "    try:\n",
    "        conflict_value = conf_value(word, model_RealismusNaturalismus)\n",
    "        lst_conflict.append(conflict_value)\n",
    "        dict_conflict[word] = conflict_value\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16afec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Realismus_LEMMATIZED:\n",
    "    \n",
    "    lst_conflict_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_conflict_phrase.append(dict_conflict[word])\n",
    "    \n",
    "    mean_conf_phrase = sum(lst_conflict_phrase) / len(lst_conflict_phrase)\n",
    "    \n",
    "    df_VPs_Realismus.at[i,'mean_conf_dornseiff'] = mean_conf_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c5e101d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[es, klopfte, hart, und, kurz, an, die, tür]</td>\n",
       "      <td>[ich, klopfen, hart, und, kurz, an, der, tür]</td>\n",
       "      <td>-0.051287</td>\n",
       "      <td>-0.029731</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>-0.014026</td>\n",
       "      <td>0.239272</td>\n",
       "      <td>0.00693</td>\n",
       "      <td>0.01286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[obgleich, irene, seit, vielen, stunden, bald,...</td>\n",
       "      <td>[obgleich, irene, seit, viel, stunde, bald, wa...</td>\n",
       "      <td>-0.023664</td>\n",
       "      <td>-0.023765</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.028803</td>\n",
       "      <td>0.25432</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fuhr, sie, nun, doch, erschreckt, zusammen]</td>\n",
       "      <td>[fahren, ich, nun, doch, erschrecken, zusammen]</td>\n",
       "      <td>-0.043396</td>\n",
       "      <td>-0.008009</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.033831</td>\n",
       "      <td>0.252944</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[die, ganze, nacht, hatte, sie, keinen, rechte...</td>\n",
       "      <td>[der, ganze, nacht, haben, ich, kein, recht, s...</td>\n",
       "      <td>-0.027959</td>\n",
       "      <td>-0.033338</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.035174</td>\n",
       "      <td>0.273068</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[und, nun, schien, es, ihr, als, wären, ihre, ...</td>\n",
       "      <td>[und, nun, scheinen, ich, mein, als, sein, mei...</td>\n",
       "      <td>-0.037474</td>\n",
       "      <td>-0.032536</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>-0.044963</td>\n",
       "      <td>0.29948</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0       [es, klopfte, hart, und, kurz, an, die, tür]   \n",
       "1  [obgleich, irene, seit, vielen, stunden, bald,...   \n",
       "2       [fuhr, sie, nun, doch, erschreckt, zusammen]   \n",
       "3  [die, ganze, nacht, hatte, sie, keinen, rechte...   \n",
       "4  [und, nun, schien, es, ihr, als, wären, ihre, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0      [ich, klopfen, hart, und, kurz, an, der, tür]    -0.051287   \n",
       "1  [obgleich, irene, seit, viel, stunde, bald, wa...    -0.023664   \n",
       "2    [fahren, ich, nun, doch, erschrecken, zusammen]    -0.043396   \n",
       "3  [der, ganze, nacht, haben, ich, kein, recht, s...    -0.027959   \n",
       "4  [und, nun, scheinen, ich, mein, als, sein, mei...    -0.037474   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.029731   -0.001594     -0.014026      0.239272      0.00693   \n",
       "1    -0.023765   -0.000829     -0.028803       0.25432     0.008266   \n",
       "2    -0.008009    0.001012     -0.033831      0.252944     0.009461   \n",
       "3    -0.033338   -0.001239     -0.035174      0.273068     0.011571   \n",
       "4    -0.032536   -0.001683     -0.044963       0.29948     0.015282   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation       novel_title novel_beg  \\\n",
       "0             0.01286                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "1            0.010286                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "2            0.030593                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "3            0.012095                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "4            0.014476                  NaN  Boy-Ed_Ida_Empor         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      6496          0  \n",
       "1      6496          1  \n",
       "2      6496          2  \n",
       "3      6496          3  \n",
       "4      6496          4  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Realismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb31f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f26172a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATURALISMUS\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_conflict = {}\n",
    "lst_conflict = []\n",
    "\n",
    "for word in list(set(lst_words_Naturalismus_LEMMATIZED)):\n",
    "    try:\n",
    "        conflict_value = conf_value(word, model_RealismusNaturalismus)\n",
    "        lst_conflict.append(conflict_value)\n",
    "        dict_conflict[word] = conflict_value\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34302b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Naturalismus_LEMMATIZED:\n",
    "    \n",
    "    lst_conflict_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_conflict_phrase.append(dict_conflict[word])\n",
    "    \n",
    "    mean_conf_phrase = sum(lst_conflict_phrase) / len(lst_conflict_phrase)\n",
    "    \n",
    "    df_VPs_Naturalismus.at[i,'mean_conf_dornseiff'] = mean_conf_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7bcb613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, der, morgenstille, war, nichts, vernehmba...</td>\n",
       "      <td>[in, der, morgenstille, sein, nichts, vernehmb...</td>\n",
       "      <td>-0.041573</td>\n",
       "      <td>-0.009479</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.018016</td>\n",
       "      <td>0.236784</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>-0.001981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[die, sich, nicht, weit, von, der, russischen,...</td>\n",
       "      <td>[der, sich, nicht, weit, von, der, russisch, h...</td>\n",
       "      <td>-0.017482</td>\n",
       "      <td>-0.012251</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.002285</td>\n",
       "      <td>0.230448</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[die, breite, ungepflasterte, straße, die, sic...</td>\n",
       "      <td>[der, breit, ungepflasterte, straße, der, sich...</td>\n",
       "      <td>-0.023813</td>\n",
       "      <td>-0.023564</td>\n",
       "      <td>-0.00089</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>0.223625</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dann, holperte, ein, leiterwagen, mit, einige...</td>\n",
       "      <td>[dann, holpern, einen, leiterwagen, mit, einig...</td>\n",
       "      <td>-0.05482</td>\n",
       "      <td>-0.040984</td>\n",
       "      <td>-0.00252</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.213727</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, fuhrmann, kletterte, von, seinem, sitz, ...</td>\n",
       "      <td>[der, fuhrmann, klettern, von, mein, sitz, wer...</td>\n",
       "      <td>-0.04453</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.015741</td>\n",
       "      <td>0.23927</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [in, der, morgenstille, war, nichts, vernehmba...   \n",
       "1  [die, sich, nicht, weit, von, der, russischen,...   \n",
       "2  [die, breite, ungepflasterte, straße, die, sic...   \n",
       "3  [dann, holperte, ein, leiterwagen, mit, einige...   \n",
       "4  [der, fuhrmann, kletterte, von, seinem, sitz, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [in, der, morgenstille, sein, nichts, vernehmb...    -0.041573   \n",
       "1  [der, sich, nicht, weit, von, der, russisch, h...    -0.017482   \n",
       "2  [der, breit, ungepflasterte, straße, der, sich...    -0.023813   \n",
       "3  [dann, holpern, einen, leiterwagen, mit, einig...     -0.05482   \n",
       "4  [der, fuhrmann, klettern, von, mein, sitz, wer...     -0.04453   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.009479   -0.000255     -0.018016      0.236784     0.005706   \n",
       "1    -0.012251   -0.000511     -0.002285      0.230448       0.0063   \n",
       "2    -0.023564    -0.00089     -0.005926      0.223625     0.005873   \n",
       "3    -0.040984    -0.00252     -0.011334      0.213727     0.004154   \n",
       "4    -0.022021   -0.001098     -0.015741       0.23927     0.005927   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation              novel_title novel_beg  \\\n",
       "0           -0.001981                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "1            0.004817                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "2            0.002291                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "3            0.033816                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "4            0.006729                  NaN  Andreas-Salome_Lou_Ruth         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      8249          0  \n",
       "1      8249          1  \n",
       "2      8249          2  \n",
       "3      8249          3  \n",
       "4      8249          4  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Naturalismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ec087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c72094c6",
   "metadata": {},
   "source": [
    "#### Approach 3 (Annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe29d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels\n",
    "\n",
    "lst_high_conflict = ['bedenklich',\n",
    " 'ängstlich',\n",
    " 'grausam',\n",
    " 'gewehr',\n",
    " 'ballen',\n",
    " 'stechen',\n",
    " 'messer',\n",
    " 'einschlagen',\n",
    " 'gehorchen',\n",
    " 'schelten']\n",
    "\n",
    "\n",
    "\n",
    "lst_low_conflict = ['trösten',\n",
    " 'reich',\n",
    " 'beruhigen',\n",
    " 'gewinnen',\n",
    " 'rücken',\n",
    " 'bitten',\n",
    " 'leicht' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0abaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f4eac6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROMANTIK\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_conflict = {}\n",
    "lst_conflict = []\n",
    "\n",
    "for word in list(set(lst_words_Romantik_core_LEMMATIZED)):\n",
    "    try:\n",
    "        conflict_value = conf_value(word, model_Romantik)\n",
    "        lst_conflict.append(conflict_value)\n",
    "        dict_conflict[word] = conflict_value\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c532d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Romantik_core_LEMMATIZED:\n",
    "    \n",
    "    lst_conflict_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_conflict_phrase.append(dict_conflict[word])\n",
    "    \n",
    "    mean_conf_phrase = sum(lst_conflict_phrase) / len(lst_conflict_phrase)\n",
    "    \n",
    "    df_VPs_Romantik_core.at[i,'mean_conf_annotation'] = mean_conf_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6d5eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dem, schutzgeist, bleibt, ein, treuer, sinn, ...</td>\n",
       "      <td>[der, schutzgeist, bleiben, einen, treu, sinn,...</td>\n",
       "      <td>-0.008388</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.224101</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>-0.016558</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[so, ward, auch, mir, ein, hochgesellig, leben...</td>\n",
       "      <td>[so, ward, auch, sich, einen, hochgesellig, le...</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>-0.007146</td>\n",
       "      <td>-0.024458</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wo, sich, die, worte, leicht, zum, lied, gere...</td>\n",
       "      <td>[wo, sich, der, wort, leicht, zum, lied, reihen]</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.211023</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>-0.01941</td>\n",
       "      <td>-0.033575</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mein, lied, und, ich, wir, bleiben, treu, erg...</td>\n",
       "      <td>[mein, lied, und, ich, ich, bleiben, treu, erg...</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>-0.011589</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.267624</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>-0.022191</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, uns, hat, durch, melodie, geweiht]</td>\n",
       "      <td>[der, sich, haben, durch, melodie, weihen]</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.249832</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>-0.008013</td>\n",
       "      <td>-0.029408</td>\n",
       "      <td>Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>17602</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [dem, schutzgeist, bleibt, ein, treuer, sinn, ...   \n",
       "1  [so, ward, auch, mir, ein, hochgesellig, leben...   \n",
       "2  [wo, sich, die, worte, leicht, zum, lied, gere...   \n",
       "3  [mein, lied, und, ich, wir, bleiben, treu, erg...   \n",
       "4           [der, uns, hat, durch, melodie, geweiht]   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [der, schutzgeist, bleiben, einen, treu, sinn,...    -0.008388   \n",
       "1  [so, ward, auch, sich, einen, hochgesellig, le...     0.000133   \n",
       "2   [wo, sich, der, wort, leicht, zum, lied, reihen]    -0.000316   \n",
       "3  [mein, lied, und, ich, ich, bleiben, treu, erg...    -0.002559   \n",
       "4         [der, sich, haben, durch, melodie, weihen]     0.021854   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0     0.007577   -0.000145      0.007036      0.224101     0.006323   \n",
       "1    -0.000132   -0.000119      0.007223      0.257948     0.005676   \n",
       "2    -0.002302   -0.000048      0.009215      0.211023     0.005506   \n",
       "3    -0.011589   -0.000559      0.013513      0.267624     0.006237   \n",
       "4     0.004098   -0.000289     -0.004865      0.249832     0.006091   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation  \\\n",
       "0            0.004102            -0.016558   \n",
       "1           -0.007146            -0.024458   \n",
       "2            -0.01941            -0.033575   \n",
       "3            0.006048            -0.022191   \n",
       "4           -0.008013            -0.029408   \n",
       "\n",
       "                                         novel_title novel_beg novel_end  \\\n",
       "0  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "1  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "2  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "3  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "4  Arnim_Achim_von_Armut,_Reichtum,_Schuld_und_Bu...         0     17602   \n",
       "\n",
       "  phrase_pos  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Romantik_core.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367a9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8529627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REALISMUS\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_conflict = {}\n",
    "lst_conflict = []\n",
    "\n",
    "for word in list(set(lst_words_Realismus_LEMMATIZED)):\n",
    "    try:\n",
    "        conflict_value = conf_value(word, model_RealismusNaturalismus)\n",
    "        lst_conflict.append(conflict_value)\n",
    "        dict_conflict[word] = conflict_value\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1edf8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Realismus_LEMMATIZED:\n",
    "    \n",
    "    lst_conflict_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_conflict_phrase.append(dict_conflict[word])\n",
    "    \n",
    "    mean_conf_phrase = sum(lst_conflict_phrase) / len(lst_conflict_phrase)\n",
    "    \n",
    "    df_VPs_Realismus.at[i,'mean_conf_annotation'] = mean_conf_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a9a3a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[es, klopfte, hart, und, kurz, an, die, tür]</td>\n",
       "      <td>[ich, klopfen, hart, und, kurz, an, der, tür]</td>\n",
       "      <td>-0.051287</td>\n",
       "      <td>-0.029731</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>-0.014026</td>\n",
       "      <td>0.239272</td>\n",
       "      <td>0.00693</td>\n",
       "      <td>0.01286</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[obgleich, irene, seit, vielen, stunden, bald,...</td>\n",
       "      <td>[obgleich, irene, seit, viel, stunde, bald, wa...</td>\n",
       "      <td>-0.023664</td>\n",
       "      <td>-0.023765</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.028803</td>\n",
       "      <td>0.25432</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fuhr, sie, nun, doch, erschreckt, zusammen]</td>\n",
       "      <td>[fahren, ich, nun, doch, erschrecken, zusammen]</td>\n",
       "      <td>-0.043396</td>\n",
       "      <td>-0.008009</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.033831</td>\n",
       "      <td>0.252944</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[die, ganze, nacht, hatte, sie, keinen, rechte...</td>\n",
       "      <td>[der, ganze, nacht, haben, ich, kein, recht, s...</td>\n",
       "      <td>-0.027959</td>\n",
       "      <td>-0.033338</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.035174</td>\n",
       "      <td>0.273068</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[und, nun, schien, es, ihr, als, wären, ihre, ...</td>\n",
       "      <td>[und, nun, scheinen, ich, mein, als, sein, mei...</td>\n",
       "      <td>-0.037474</td>\n",
       "      <td>-0.032536</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>-0.044963</td>\n",
       "      <td>0.29948</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>Boy-Ed_Ida_Empor</td>\n",
       "      <td>0</td>\n",
       "      <td>6496</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0       [es, klopfte, hart, und, kurz, an, die, tür]   \n",
       "1  [obgleich, irene, seit, vielen, stunden, bald,...   \n",
       "2       [fuhr, sie, nun, doch, erschreckt, zusammen]   \n",
       "3  [die, ganze, nacht, hatte, sie, keinen, rechte...   \n",
       "4  [und, nun, schien, es, ihr, als, wären, ihre, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0      [ich, klopfen, hart, und, kurz, an, der, tür]    -0.051287   \n",
       "1  [obgleich, irene, seit, viel, stunde, bald, wa...    -0.023664   \n",
       "2    [fahren, ich, nun, doch, erschrecken, zusammen]    -0.043396   \n",
       "3  [der, ganze, nacht, haben, ich, kein, recht, s...    -0.027959   \n",
       "4  [und, nun, scheinen, ich, mein, als, sein, mei...    -0.037474   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.029731   -0.001594     -0.014026      0.239272      0.00693   \n",
       "1    -0.023765   -0.000829     -0.028803       0.25432     0.008266   \n",
       "2    -0.008009    0.001012     -0.033831      0.252944     0.009461   \n",
       "3    -0.033338   -0.001239     -0.035174      0.273068     0.011571   \n",
       "4    -0.032536   -0.001683     -0.044963       0.29948     0.015282   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation       novel_title novel_beg  \\\n",
       "0             0.01286             0.029283  Boy-Ed_Ida_Empor         0   \n",
       "1            0.010286             0.008729  Boy-Ed_Ida_Empor         0   \n",
       "2            0.030593             0.004349  Boy-Ed_Ida_Empor         0   \n",
       "3            0.012095             0.013931  Boy-Ed_Ida_Empor         0   \n",
       "4            0.014476             0.013893  Boy-Ed_Ida_Empor         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      6496          0  \n",
       "1      6496          1  \n",
       "2      6496          2  \n",
       "3      6496          3  \n",
       "4      6496          4  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Realismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c263a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73dcabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATURALISMUS\n",
    "\n",
    "#determine values for all types\n",
    "\n",
    "dict_conflict = {}\n",
    "lst_conflict = []\n",
    "\n",
    "for word in list(set(lst_words_Naturalismus_LEMMATIZED)):\n",
    "    try:\n",
    "        conflict_value = conf_value(word, model_RealismusNaturalismus)\n",
    "        lst_conflict.append(conflict_value)\n",
    "        dict_conflict[word] = conflict_value\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c554686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for phrase in lst_phrases_Naturalismus_LEMMATIZED:\n",
    "    \n",
    "    lst_conflict_phrase = []\n",
    "    \n",
    "    for word in phrase:\n",
    "        lst_conflict_phrase.append(dict_conflict[word])\n",
    "    \n",
    "    mean_conf_phrase = sum(lst_conflict_phrase) / len(lst_conflict_phrase)\n",
    "    \n",
    "    df_VPs_Naturalismus.at[i,'mean_conf_annotation'] = mean_conf_phrase\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe6eda24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>phrase_lemmatized</th>\n",
       "      <th>mean_val_adj</th>\n",
       "      <th>mean_aro_adj</th>\n",
       "      <th>mean_ep_adj</th>\n",
       "      <th>mean_val_noun</th>\n",
       "      <th>mean_aro_noun</th>\n",
       "      <th>mean_ep_noun</th>\n",
       "      <th>mean_conf_dornseiff</th>\n",
       "      <th>mean_conf_annotation</th>\n",
       "      <th>novel_title</th>\n",
       "      <th>novel_beg</th>\n",
       "      <th>novel_end</th>\n",
       "      <th>phrase_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[in, der, morgenstille, war, nichts, vernehmba...</td>\n",
       "      <td>[in, der, morgenstille, sein, nichts, vernehmb...</td>\n",
       "      <td>-0.041573</td>\n",
       "      <td>-0.009479</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.018016</td>\n",
       "      <td>0.236784</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>-0.001981</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[die, sich, nicht, weit, von, der, russischen,...</td>\n",
       "      <td>[der, sich, nicht, weit, von, der, russisch, h...</td>\n",
       "      <td>-0.017482</td>\n",
       "      <td>-0.012251</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.002285</td>\n",
       "      <td>0.230448</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.016264</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[die, breite, ungepflasterte, straße, die, sic...</td>\n",
       "      <td>[der, breit, ungepflasterte, straße, der, sich...</td>\n",
       "      <td>-0.023813</td>\n",
       "      <td>-0.023564</td>\n",
       "      <td>-0.00089</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>0.223625</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dann, holperte, ein, leiterwagen, mit, einige...</td>\n",
       "      <td>[dann, holpern, einen, leiterwagen, mit, einig...</td>\n",
       "      <td>-0.05482</td>\n",
       "      <td>-0.040984</td>\n",
       "      <td>-0.00252</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.213727</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.043843</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[der, fuhrmann, kletterte, von, seinem, sitz, ...</td>\n",
       "      <td>[der, fuhrmann, klettern, von, mein, sitz, wer...</td>\n",
       "      <td>-0.04453</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.015741</td>\n",
       "      <td>0.23927</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.032351</td>\n",
       "      <td>Andreas-Salome_Lou_Ruth</td>\n",
       "      <td>0</td>\n",
       "      <td>8249</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    phrase_tokenized  \\\n",
       "0  [in, der, morgenstille, war, nichts, vernehmba...   \n",
       "1  [die, sich, nicht, weit, von, der, russischen,...   \n",
       "2  [die, breite, ungepflasterte, straße, die, sic...   \n",
       "3  [dann, holperte, ein, leiterwagen, mit, einige...   \n",
       "4  [der, fuhrmann, kletterte, von, seinem, sitz, ...   \n",
       "\n",
       "                                   phrase_lemmatized mean_val_adj  \\\n",
       "0  [in, der, morgenstille, sein, nichts, vernehmb...    -0.041573   \n",
       "1  [der, sich, nicht, weit, von, der, russisch, h...    -0.017482   \n",
       "2  [der, breit, ungepflasterte, straße, der, sich...    -0.023813   \n",
       "3  [dann, holpern, einen, leiterwagen, mit, einig...     -0.05482   \n",
       "4  [der, fuhrmann, klettern, von, mein, sitz, wer...     -0.04453   \n",
       "\n",
       "  mean_aro_adj mean_ep_adj mean_val_noun mean_aro_noun mean_ep_noun  \\\n",
       "0    -0.009479   -0.000255     -0.018016      0.236784     0.005706   \n",
       "1    -0.012251   -0.000511     -0.002285      0.230448       0.0063   \n",
       "2    -0.023564    -0.00089     -0.005926      0.223625     0.005873   \n",
       "3    -0.040984    -0.00252     -0.011334      0.213727     0.004154   \n",
       "4    -0.022021   -0.001098     -0.015741       0.23927     0.005927   \n",
       "\n",
       "  mean_conf_dornseiff mean_conf_annotation              novel_title novel_beg  \\\n",
       "0           -0.001981             0.021268  Andreas-Salome_Lou_Ruth         0   \n",
       "1            0.004817             0.016264  Andreas-Salome_Lou_Ruth         0   \n",
       "2            0.002291             0.018371  Andreas-Salome_Lou_Ruth         0   \n",
       "3            0.033816             0.043843  Andreas-Salome_Lou_Ruth         0   \n",
       "4            0.006729             0.032351  Andreas-Salome_Lou_Ruth         0   \n",
       "\n",
       "  novel_end phrase_pos  \n",
       "0      8249          0  \n",
       "1      8249          1  \n",
       "2      8249          2  \n",
       "3      8249          3  \n",
       "4      8249          4  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VPs_Naturalismus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d48b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6903d2f3",
   "metadata": {},
   "source": [
    "#### Wrap-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b54927ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes as csv\n",
    "\n",
    "df_VPs_Romantik_core.to_csv('..//Analyseergebnisse//csv//230420_df_VPs_Romantik_core.csv', encoding='utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e620ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Realismus.to_csv('..//Analyseergebnisse//csv//230420_df_VPs_Realismus.csv', encoding='utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3da49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Naturalismus.to_csv('..//Analyseergebnisse//csv//230420_df_VPs_Naturalismus.csv', encoding='utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050b65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "93875b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes as pkl\n",
    "\n",
    "df_VPs_Romantik_core.to_pickle('..//Analyseergebnisse//pickled//230420_df_VPs_Romantik_core.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afcee3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Realismus.to_pickle('..//Analyseergebnisse//pickled//230420_df_VPs_Realismus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4f654de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VPs_Naturalismus.to_pickle('..//Analyseergebnisse//pickled//230420_df_VPs_Naturalismus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fce898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1030bcac",
   "metadata": {},
   "source": [
    "Ressources used:\n",
    "\n",
    "https://github.com/jbrottrager/character-shifts-HPFFS/blob/main/scripts/10_emotionalProfiles.ipynb (last viewed: 20.04.2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61225ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
